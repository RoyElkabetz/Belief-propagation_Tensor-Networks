# Belief Propagation in Tensor Networks

As part of my MSc research, we developed a new framework for calculating approximations of gapped local Hamiltonians ground states using Tensor Networks. 
This new framework is based on the duality between Tensor Networks and Probabilistic Graphical Models (PGM), specifically Double-Edge Factor Graphs (DEFG).
We developed a new algorithm for calculating Tensor Network expectation values that is based on the famous Belief Propagation (BP) algorithm from the world of PGM.
We also proved the equivalence of BP to the well-known tensor network algorithm the trivial-Simple Update (tSU) algorithm.
Here is the code.

Hope it is not to messy. There are notebooks with examples in the Notebooks folder.

Our papper on arXiv https://arxiv.org/abs/2008.04433
 
